{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dixKtNdJhriq",
        "colab_type": "text"
      },
      "source": [
        "# **Headline Generation via Adversarial Training**\n",
        "## **Project for Statistical Natural Language Processing (COMP0087)**\n",
        "## **University College London**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**File: Adversarial Training.ipynb**\n",
        "\n",
        "**Collaborators:**\n",
        "  - Daniel Stancl (ucabds7@ucl.ac.uk)\n",
        "  - Guoliang HE (ucabggh@ucl.ac.uk)\n",
        "  - Dorota Jagnesakova (ucabdj1@ucl.ac.uk)\n",
        "  - Zakhar Borok (zcabzbo@ucl.ac.uk)\n",
        "\n",
        "<hr>\n",
        "\n",
        "### **Description:** Colab notebook intended for running adversarial training for our pre-trained generator and discriminator. The structure of adversarial training is specified within the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoJ3uJ4kiWlQ",
        "colab_type": "text"
      },
      "source": [
        "# **1 Setup**\n",
        "\n",
        "<hr>\n",
        "\n",
        "- install and import libraries\n",
        "- remove and clone the most recent version of git repository\n",
        "- run auxiliary Python scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-PdoqujiaW_",
        "colab_type": "text"
      },
      "source": [
        "## **1.1 GitHub stuff**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBwA3aeAilFH",
        "colab_type": "text"
      },
      "source": [
        "### **1.1.1 Set GitHub credentials and username of repo owner**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ay0We_0hj3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credentials\n",
        "user_email = '<your_email>'\n",
        "user = '<your_username>'\n",
        "user_password = \"<your_password>\"\n",
        "\n",
        "# username of repo owner\n",
        "owner_username = 'stancld'\n",
        "# reponame\n",
        "reponame = 'GeneratingHeadline_GANs'\n",
        "\n",
        "# generate \n",
        "add_origin_link = (\n",
        "    'https://{}:{}github@github.com/{}/{}.git'.format(\n",
        "    user, user_password, owner_username, reponame)\n",
        ")\n",
        "\n",
        "print(\"Link used for git cooperation:\\n{}\".format(add_origin_link))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnAeQe-Pi5OP",
        "colab_type": "text"
      },
      "source": [
        "### **1.1.2 Clone GitHub repo on the personal drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHJuTxPci46_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "## Clone GitHub repo to the desired folder\n",
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "%cd \"drive/My Drive/projects\"\n",
        "\n",
        "# Remove NLP_Project if presented and clone up-to-date repo\n",
        "!rm -r GeneratingHeadline_GANs\n",
        "!git clone https://github.com/stancld/GeneratingHeadline_GANs.git\n",
        "\n",
        "# Go to the NLP_Project folder\n",
        "%cd GeneratingHeadline_GANs\n",
        "\n",
        "# Config global user and add origin enabling us to execute push commands\n",
        "!git config --global user.email user_email\n",
        "!git remote rm origin\n",
        "!git remote add origin https://<your_username>:<your_password>@github.com/stancld/GeneratingHeadline_GANs.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q46T4fRjKWX",
        "colab_type": "text"
      },
      "source": [
        "### **1.1.3 Helper function: push_to_repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFxVTx2VjKpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def push_to_repo():\n",
        "  \"\"\"\n",
        "  Helper function that pushes saved fils to github repo.\n",
        "  \"\"\"\n",
        "  !git remote rm origin\n",
        "  !git remote add origin https://<your_username>:<your_password>@github.com/stancld/GeneratingHeadline_GANs.git\n",
        "  !git checkout master\n",
        "  !git pull origin master\n",
        "  !git checkout models_branch\n",
        "  !git add .\n",
        "  !git commit -m \"model state update\"\n",
        "  !git checkout master\n",
        "  !git merge models_branch\n",
        "  !git push -u origin master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHA62OOqjKRd",
        "colab_type": "text"
      },
      "source": [
        "## **1.2 General stuff**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H5CsJUHllW3",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.1 Install and import packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrocbitplhJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install rouge==1.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skBOwJhulq0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import gc\n",
        "import copy\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from rouge import Rouge\n",
        "from termcolor import colored\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJUn6pJOlucH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d04hxK6_lyQ-",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.2 Set Torch device**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXS3k9IOl1MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set torch.device to use GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAhy3doxl6uO",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.3 Run auxiliary Python scripts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc-jDg_Sl5V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for transforming data to padded array\n",
        "run Code/data2PaddedArray.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaoUMhY79Z7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the generator\n",
        "run Code/Models/Attention_seq2seq.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKXH3I-w9ZrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the training class (generator)\n",
        "run Code/Models/generator_training_class.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5locvKqJghU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the discriminator\n",
        "run Code/Models/CNN_text_clf.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EloCDex4ghKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the training class (discriminator)\n",
        "run Code/Models/discriminator_training_class.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP81SaIbgg_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adversarial training\n",
        "run Code/Models/Adversarial_Training.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAcLUlSARRBq",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.4 Necessary class for opening text & headline dictionaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpU2YwWuRRcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class Language Dictionary\n",
        "class LangDict:\n",
        "  \"\"\"\n",
        "  Source: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"sos\", 1: \"eos\"}\n",
        "    self.n_words = 2\n",
        "\n",
        "  def add_article(self, article):\n",
        "    for word in article:\n",
        "      self.add_word(word)\n",
        "\n",
        "  def add_word(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmnNs5CW9hIF",
        "colab_type": "text"
      },
      "source": [
        "# **2. Load the data**\n",
        "\n",
        "<hr>\n",
        "\n",
        "- Text_data & headline_data (splitted into train, dev and test set)\n",
        "- Pretrained GloVe embeddings\n",
        "- text and headline dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBPX_L5j-jKe",
        "colab_type": "text"
      },
      "source": [
        "## **2.1 WikiHow data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLS8qvNtJpSO",
        "colab_type": "text"
      },
      "source": [
        "### **2.1.1 Input nad target data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMb72dgo96dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set\n",
        "text_train = np.load(\n",
        "    '../data/text_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_train = np.load(\n",
        "    '../data/headline_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Dev set\n",
        "text_val = np.load(\n",
        "    '../data/text_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_val = np.load(\n",
        "    '../data/headline_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Test set\n",
        "text_test = np.load(\n",
        "    '../data/text_test.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_test = np.load(\n",
        "    '../data/headline_test.npy',\n",
        "    allow_pickle = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnaIzizJJwvw",
        "colab_type": "text"
      },
      "source": [
        "### **2.1.2 Lengths of the input and target data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFnqCkDJwg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set\n",
        "text_lengths_train = np.load(\n",
        "    '../data/text_lengths_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_lengths_train = np.load(\n",
        "    '../data/headline_lengths_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Dev set\n",
        "text_lengths_val = np.load(\n",
        "    '../data/text_lengths_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_lengths_val = np.load(\n",
        "    '../data/headline_lengths_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Test set\n",
        "text_lengths_test = np.load(\n",
        "    '../data/text_lengths_test.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_lengths_test = np.load(\n",
        "    '../data/headline_lengths_test.npy',\n",
        "    allow_pickle = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br07eFIB-99H",
        "colab_type": "text"
      },
      "source": [
        "## **2.2 Filtered GloVe embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_LjEHCB_BCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embeddings for the text dictionry\n",
        "pre_train_weight = np.load(\n",
        "    '../data/embedding.npy'\n",
        ")\n",
        "\n",
        "# Embeddings for the headline dictionary\n",
        "pre_train_weight_head = np.load(\n",
        "    '../data/embedding_headline.npy'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG7p0DGN_xpC",
        "colab_type": "text"
      },
      "source": [
        "## **2.3 Headline & text dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlA9Ixxg_1kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text_dictionary\n",
        "with open('../data/text.dictionary', 'rb') as text_dictionary_file:\n",
        "  text_dictionary = pickle.load(text_dictionary_file)\n",
        "\n",
        "# headline_dictionary\n",
        "with open('../data/headline.dictionary', 'rb') as headline_dictionary_file:\n",
        "  headline_dictionary = pickle.load(headline_dictionary_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-dKXfYxLSRL",
        "colab_type": "text"
      },
      "source": [
        "# **3 ADVERSARIAL TRAINING**\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LDfJDPWMVb9",
        "colab_type": "text"
      },
      "source": [
        "## **3.1 Load/Initialize pre-trained generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0FEGfKWLei1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Model & Training specification #####\n",
        "model_size = 512\n",
        "grid = {'max_epochs': 25,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 3e-4,\n",
        "        'clip': 10,\n",
        "        'l2_reg': 1e-4,\n",
        "        'model_name': f\"generator{model_size:.0f}\"\n",
        "      }\n",
        "\n",
        "OUTPUT_DIM = len(headline_dictionary.index2word.keys()) # number of output classes\n",
        "ENC_EMB_DIM = pre_train_weight.shape[1] # embedding dimension\n",
        "ENC_HID_DIM = model_size # size of the RNN layer\n",
        "DEC_HID_DIM = model_size # size of the RNN layer\n",
        "\n",
        "enc_num_layers = 1 # number of layers in RNN\n",
        "dec_num_layers = 1 # number of layers in RNN\n",
        "\n",
        "ENC_DROPOUT = 0.1 # probability used for dropout in the encoder RNN unit\n",
        "DEC_DROPOUT = 0.1 # probability used for dropout in the decoder RNN unit\n",
        "##########################################\n",
        "\n",
        "\n",
        "# Initialization the model and load the state\n",
        "Generator = generator(model = _Seq2Seq, loss_function = nn.CrossEntropyLoss, optimiser = optim.Adam, l2_reg = grid['l2_reg'], batch_size = grid['batch_size'],\n",
        "                    text_dictionary = text_dictionary, embeddings = pre_train_weight, max_epochs = grid['max_epochs'], learning_rate = grid['learning_rate'],\n",
        "                    clip = grid['clip'], teacher_forcing_ratio = 1, OUTPUT_DIM = OUTPUT_DIM, ENC_HID_DIM = ENC_HID_DIM, ENC_EMB_DIM = ENC_EMB_DIM,\n",
        "                    DEC_HID_DIM = DEC_HID_DIM, ENC_DROPOUT = ENC_DROPOUT, DEC_DROPOUT = DEC_DROPOUT, enc_num_layers = enc_num_layers, dec_num_layers = dec_num_layers,\n",
        "                    device = device, model_name = grid['model_name'], push_to_repo = push_to_repo)\n",
        "Generator.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y5jfRXwMcEw",
        "colab_type": "text"
      },
      "source": [
        "## **3.2 Load/Initialize pre-trained discriminator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FEVIQGwMccM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Model & Training specification #####\n",
        "param = {'max_epochs': 80,\n",
        "            'learning_rate': 5e-4,\n",
        "            'batch_size': 32,               \n",
        "            'seq_len': 68,                   # length of your summary\n",
        "            'embed_dim': 200,\n",
        "            'drop_out': 0.5,\n",
        "            'kernel_num': 50,                 # number of your feature map\n",
        "            'in_channel': 1,                 # for text classification should be one\n",
        "            # how many conv net are used in parallel in text classification\n",
        "            'parallel_layer': 3,\n",
        "            'model_name': 'n_{:.0f}_d_{:.0f}'.format(50, 10*0.5),\n",
        "            'device':'cuda'}\n",
        "##########################################\n",
        "\n",
        "\n",
        "# Initialization the model and load the state\n",
        "Discriminator = Discriminator_utility(pre_train_weight_head,**param)\n",
        "Discriminator.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYBgb7Tmhodf",
        "colab_type": "text"
      },
      "source": [
        "## **3.3 Adversarial Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxAcOlgThplB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Model & Training specification #####\n",
        "grid = {'max_epochs': 2,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate_D': 5e-4,\n",
        "        'learning_rate_G': 1e-3,\n",
        "        'G_multiple': 2,\n",
        "        'l2_reg': 0.1,      # appled only for discriminator\n",
        "        'clip': 10,\n",
        "        'model_name': 'Adversarial_v02',\n",
        "        'text_dictionary': text_dictionary,\n",
        "        'headline_dictionary': headline_dictionary,\n",
        "        'device': 'cuda',\n",
        "        'noise_std': 0.00, \n",
        "        'optim_d_prob': 0.15 #this values determines the probability a discriminator will make step with\n",
        "        }\n",
        "\n",
        "##########################################\n",
        "\n",
        "\n",
        "# Initialization the model and load the state\n",
        "GAN = AdversarialTraining(Generator, Discriminator, optim.Adam, optim.SGD, **grid)\n",
        "GAN.load()  # if any"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNXo-X9hzTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAN.training(text_train, text_lengths_train,\n",
        "             headline_train, headline_lengths_train,\n",
        "             text_val, text_lengths_val,\n",
        "             headline_val, headline_lengths_val)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}