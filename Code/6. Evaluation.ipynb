{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dixKtNdJhriq",
        "colab_type": "text"
      },
      "source": [
        "# **Headline Generation via Adversarial Training**\n",
        "## **Project for Statistical Natural Language Processing (COMP0087)**\n",
        "## **University College London**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**File: Evaluation.ipynb**\n",
        "\n",
        "**Collaborators:**\n",
        "  - Daniel Stancl (ucabds7@ucl.ac.uk)\n",
        "  - Guoliang HE (ucabggh@ucl.ac.uk)\n",
        "  - Dorota Jagnesakova (ucabdj1@ucl.ac.uk)\n",
        "  - Zakhar Borok (zcabzbo@ucl.ac.uk)\n",
        "\n",
        "<hr>\n",
        "\n",
        "### **Description:** Evaluation notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoJ3uJ4kiWlQ",
        "colab_type": "text"
      },
      "source": [
        "# **1 Setup**\n",
        "\n",
        "<hr>\n",
        "\n",
        "- install and import libraries\n",
        "- remove and clone the most recent version of git repository\n",
        "- run auxiliary Python scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-PdoqujiaW_",
        "colab_type": "text"
      },
      "source": [
        "## **1.1 GitHub stuff**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBwA3aeAilFH",
        "colab_type": "text"
      },
      "source": [
        "### **1.1.1 Set GitHub credentials and username of repo owner**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ay0We_0hj3G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75f83928-406e-4b76-8571-f6cff99a7cbd"
      },
      "source": [
        "# credentials\n",
        "user_email = '<your_email>'\n",
        "user = '<your_username>'\n",
        "user_password = \"<your_password>\"\n",
        "\n",
        "# username of repo owner\n",
        "owner_username = 'stancld'\n",
        "# reponame\n",
        "reponame = 'GeneratingHeadline_GANs'\n",
        "\n",
        "# generate \n",
        "add_origin_link = (\n",
        "    'https://{}:{}github@github.com/{}/{}.git'.format(\n",
        "    user, user_password, owner_username, reponame)\n",
        ")\n",
        "\n",
        "print(\"Link used for git cooperation:\\n{}\".format(add_origin_link))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Link used for git cooperation:\n",
            "https://<your_username>:<your_password>github@github.com/stancld/GeneratingHeadline_GANs.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnAeQe-Pi5OP",
        "colab_type": "text"
      },
      "source": [
        "### **1.1.2 Clone GitHub repo on the personal drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHJuTxPci46_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "bc444724-4274-4b8e-9eaf-30de714954cb"
      },
      "source": [
        "%%time\n",
        "\n",
        "## Clone GitHub repo to the desired folder\n",
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "%cd \"drive/My Drive/projects\"\n",
        "\n",
        "# Remove NLP_Project if presented and clone up-to-date repo\n",
        "!rm -r GeneratingHeadline_GANs\n",
        "!git clone https://github.com/stancld/GeneratingHeadline_GANs.git\n",
        "\n",
        "# Go to the NLP_Project folder\n",
        "%cd GeneratingHeadline_GANs\n",
        "\n",
        "# Config global user and add origin enabling us to execute push commands\n",
        "!git config --global user.email user_email\n",
        "!git remote rm origin\n",
        "!git remote add origin https://<your_username>:<your_password>@github.com/stancld/GeneratingHeadline_GANs.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/projects\n",
            "Cloning into 'GeneratingHeadline_GANs'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 2340 (delta 16), reused 19 (delta 7), pack-reused 2311\u001b[K\n",
            "Receiving objects: 100% (2340/2340), 19.60 MiB | 20.07 MiB/s, done.\n",
            "Resolving deltas: 100% (1517/1517), done.\n",
            "Checking out files: 100% (151/151), done.\n",
            "/content/drive/My Drive/projects/GeneratingHeadline_GANs\n",
            "/bin/bash: your_username: No such file or directory\n",
            "CPU times: user 199 ms, sys: 89.5 ms, total: 288 ms\n",
            "Wall time: 11.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q46T4fRjKWX",
        "colab_type": "text"
      },
      "source": [
        "### **1.1.3 Helper function: push_to_repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFxVTx2VjKpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def push_to_repo():\n",
        "  \"\"\"\n",
        "  Helper function that pushes saved fils to github repo.\n",
        "  \"\"\"\n",
        "  !git remote rm origin\n",
        "  !git remote add origin https://<your_username>:<your_password>@github.com/stancld/GeneratingHeadline_GANs.git\n",
        "  !git checkout master\n",
        "  !git pull origin master\n",
        "  !git checkout models_branch\n",
        "  !git add .\n",
        "  !git commit -m \"model state update\"\n",
        "  !git checkout master\n",
        "  !git merge models_branch\n",
        "  !git push -u origin master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHA62OOqjKRd",
        "colab_type": "text"
      },
      "source": [
        "## **1.2 General stuff**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H5CsJUHllW3",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.1 Install and import packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrocbitplhJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f8787094-029b-492d-eb4d-6f60ce9478ea"
      },
      "source": [
        "pip install rouge==1.0.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge==1.0.0) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skBOwJhulq0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import gc\n",
        "import copy\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from rouge import Rouge\n",
        "from termcolor import colored\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJUn6pJOlucH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2df5671e-bd63-4234-f13b-645d4c4a6842"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d04hxK6_lyQ-",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.2 Set Torch device**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXS3k9IOl1MD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddae9508-ef9c-4146-e816-01c45c1c5068"
      },
      "source": [
        "# Set torch.device to use GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAhy3doxl6uO",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.3 Run auxiliary Python scripts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc-jDg_Sl5V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for transforming data to padded array\n",
        "run Code/data2PaddedArray.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaoUMhY79Z7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the generator\n",
        "run Code/Models/Attention_seq2seq.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKXH3I-w9ZrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the training class (generator)\n",
        "run Code/Models/generator_training_class.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5locvKqJghU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the discriminator\n",
        "run Code/Models/CNN_text_clf.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EloCDex4ghKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the training class (discriminator)\n",
        "run Code/Models/discriminator_training_class.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP81SaIbgg_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adversarial training\n",
        "run Code/Models/Adversarial_Training.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAcLUlSARRBq",
        "colab_type": "text"
      },
      "source": [
        "### **1.2.4 Necessary class for opening text & headline dictionaries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpU2YwWuRRcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Class Language Dictionary\n",
        "class LangDict:\n",
        "  \"\"\"\n",
        "  Source: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"sos\", 1: \"eos\"}\n",
        "    self.n_words = 2\n",
        "\n",
        "  def add_article(self, article):\n",
        "    for word in article:\n",
        "      self.add_word(word)\n",
        "\n",
        "  def add_word(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmnNs5CW9hIF",
        "colab_type": "text"
      },
      "source": [
        "# **2. Load the data**\n",
        "\n",
        "<hr>\n",
        "\n",
        "- Text_data & headline_data (splitted into train, dev and test set)\n",
        "- Pretrained GloVe embeddings\n",
        "- text and headline dictionaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBPX_L5j-jKe",
        "colab_type": "text"
      },
      "source": [
        "## **2.1 WikiHow data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLS8qvNtJpSO",
        "colab_type": "text"
      },
      "source": [
        "### **2.1.1 Input nad target data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMb72dgo96dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set\n",
        "text_train = np.load(\n",
        "    '../data/text_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_train = np.load(\n",
        "    '../data/headline_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Dev set\n",
        "text_val = np.load(\n",
        "    '../data/text_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_val = np.load(\n",
        "    '../data/headline_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Test set\n",
        "text_test = np.load(\n",
        "    '../data/text_test.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_test = np.load(\n",
        "    '../data/headline_test.npy',\n",
        "    allow_pickle = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnaIzizJJwvw",
        "colab_type": "text"
      },
      "source": [
        "### **2.1.2 Lengths of the input and target data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVFnqCkDJwg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set\n",
        "text_lengths_train = np.load(\n",
        "    '../data/text_lengths_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_lengths_train = np.load(\n",
        "    '../data/headline_lengths_train.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Dev set\n",
        "text_lengths_val = np.load(\n",
        "    '../data/text_lengths_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_lengths_val = np.load(\n",
        "    '../data/headline_lengths_val.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "\n",
        "# Test set\n",
        "text_lengths_test = np.load(\n",
        "    '../data/text_lengths_test.npy',\n",
        "    allow_pickle = True\n",
        ")\n",
        "headline_lengths_test = np.load(\n",
        "    '../data/headline_lengths_test.npy',\n",
        "    allow_pickle = True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br07eFIB-99H",
        "colab_type": "text"
      },
      "source": [
        "## **2.2 Filtered GloVe embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_LjEHCB_BCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embeddings for the text dictionry\n",
        "pre_train_weight = np.load(\n",
        "    '../data/embedding.npy'\n",
        ")\n",
        "\n",
        "# Embeddings for the headline dictionary\n",
        "pre_train_weight_head = np.load(\n",
        "    '../data/embedding_headline.npy'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG7p0DGN_xpC",
        "colab_type": "text"
      },
      "source": [
        "## **2.3 Headline & text dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlA9Ixxg_1kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text_dictionary\n",
        "with open('../data/text.dictionary', 'rb') as text_dictionary_file:\n",
        "  text_dictionary = pickle.load(text_dictionary_file)\n",
        "\n",
        "# headline_dictionary\n",
        "with open('../data/headline.dictionary', 'rb') as headline_dictionary_file:\n",
        "  headline_dictionary = pickle.load(headline_dictionary_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-dKXfYxLSRL",
        "colab_type": "text"
      },
      "source": [
        "# **3 Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LDfJDPWMVb9",
        "colab_type": "text"
      },
      "source": [
        "## **3.1 Baseline models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnM7US7kmZwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify model sizes\n",
        "model_sizes = [128, 256, 512]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0FEGfKWLei1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialization of Rouge() and define Helper function\n",
        "rouge = Rouge()\n",
        "def rouge_get_scores(hyp, ref, n):\n",
        "  try:\n",
        "    return float(rouge.get_scores(hyp, ref)[0]['rouge-{}'.format(n)]['f'])\n",
        "  except:\n",
        "    return \"drop\" # some summaries a flawed (there is nothing to compute) so they're dropped (only a negligible number of examples!! it does merely affect average scores by some thousandths)\n",
        "\n",
        "# Define indices of <pad> and <eos> tokens\n",
        "pad_idx = headline_dictionary.word2index['<pad>']\n",
        "eos_idx = headline_dictionary.word2index['eos']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PKqSl9Ak9Jq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "13f87c12-e355-4fb7-8df5-38debb84d61f"
      },
      "source": [
        "for model_size in model_sizes:\n",
        " \n",
        " ##### Model & Training specification #####\n",
        "  grid = {'max_epochs': 25,\n",
        "          'batch_size': 32,\n",
        "          'learning_rate': 3e-4,\n",
        "          'clip': 10,\n",
        "          'l2_reg': 1e-4,\n",
        "          'model_name': \"generator{:.0f}\".format(model_size)\n",
        "        }\n",
        "\n",
        "  OUTPUT_DIM = len(headline_dictionary.index2word.keys()) # number of output classes\n",
        "  ENC_EMB_DIM = pre_train_weight.shape[1] # embedding dimension\n",
        "  ENC_HID_DIM = model_size # size of the RNN layer\n",
        "  DEC_HID_DIM = model_size # size of the RNN layer\n",
        "\n",
        "  enc_num_layers = 1 # number of layers in RNN\n",
        "  dec_num_layers = 1 # number of layers in RNN\n",
        "\n",
        "  ENC_DROPOUT = 0.1 # probability used for dropout in the encoder RNN unit\n",
        "  DEC_DROPOUT = 0.1 # probability used for dropout in the decoder RNN unit\n",
        "  ##########################################\n",
        "\n",
        "\n",
        "  # Initialization the model and load the state\n",
        "  Generator = generator(model = _Seq2Seq, loss_function = nn.CrossEntropyLoss, optimiser = optim.Adam, l2_reg = grid['l2_reg'], batch_size = grid['batch_size'],\n",
        "                      text_dictionary = text_dictionary, embeddings = pre_train_weight, max_epochs = grid['max_epochs'], learning_rate = grid['learning_rate'],\n",
        "                      clip = grid['clip'], teacher_forcing_ratio = 1, OUTPUT_DIM = OUTPUT_DIM, ENC_HID_DIM = ENC_HID_DIM, ENC_EMB_DIM = ENC_EMB_DIM,\n",
        "                      DEC_HID_DIM = DEC_HID_DIM, ENC_DROPOUT = ENC_DROPOUT, DEC_DROPOUT = DEC_DROPOUT, enc_num_layers = enc_num_layers, dec_num_layers = dec_num_layers,\n",
        "                      device = device, model_name = grid['model_name'], push_to_repo = push_to_repo)\n",
        "  Generator.load()\n",
        "\n",
        "\n",
        "  ##### ROUGE scores #####\n",
        "  # Generate hypothesis and conver them into text\n",
        "  hypotheses = Generator.generate_summaries(text_test, text_lengths_test, headline_test, headline_lengths_test)\n",
        "  hypotheses = sum(\n",
        "      [[' '.join([headline_dictionary.index2word[index] for index in batch[:, hypothesis] if (index != pad_idx) & (index != eos_idx)][1:]) for hypothesis in range(batch.shape[1])] for batch in hypotheses], []\n",
        "  )\n",
        "  \n",
        "  # Convert references into the text\n",
        "  references = [' '.join([headline_dictionary.index2word[index] for index in headline_test[:, sentence] if (index != pad_idx) & (index != eos_idx)][1:]) for sentence in range(headline_test.shape[1])]\n",
        "  \n",
        "  # trim (only full batches are generated)\n",
        "  lim = Generator.n_batches * grid['batch_size']\n",
        "  references[:lim]\n",
        "\n",
        "  # Compute average rouge scores\n",
        "  rouge1 = [rouge_get_scores(hyp, ref, '1') for hyp, ref in zip(hypotheses, references)]\n",
        "  rouge1 = np.array([x for x in rouge1 if x != 'drop']).mean()\n",
        "  rouge2 = [rouge_get_scores(hyp, ref, '2') for hyp, ref in zip(hypotheses, references)]\n",
        "  rouge2 = np.array([x for x in rouge2 if x != 'drop']).mean()\n",
        "  rougel = [rouge_get_scores(hyp, ref, 'l') for hyp, ref in zip(hypotheses, references)]\n",
        "  rougel = np.array([x for x in rougel if x != 'drop']).mean()\n",
        "  \n",
        "  # cleaning\n",
        "  del hypotheses, references\n",
        "  gc.collect()\n",
        "\n",
        "  # Print rouge scores\n",
        "  print('Model size = {:.0f}.'.format(model_size))\n",
        "  print('ROUGE-1: {:.3f} on test data.'.format(100*np.array(rouge1)))\n",
        "  print('ROUGE-2: {:.3f} on test data.'.format(100*np.array(rouge2)))\n",
        "  print('ROUGE-l: {:.3f} on test data.'.format(100*np.array(rougel)))\n",
        "  print('---------------')\n",
        "\n",
        "  # Save results\n",
        "  ROUGE = {'ROUGE-1': rouge1,\n",
        "           'ROUGE-2': rouge2,\n",
        "           'ROUGE-L': rougel}\n",
        "  json_file = json.dumps(ROUGE)\n",
        "  file = open('Results/ROUGE_{:.0f}_test.txt'.format(model_size), \"w\")\n",
        "  file.write(json_file)\n",
        "  file.close()\n",
        "\n",
        "# Push everything to github\n",
        "#push_to_repo()#"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 128.\n",
            "ROUGE-1: 14.197 on test data.\n",
            "ROUGE-2: 3.168 on test data.\n",
            "ROUGE-l: 14.210 on test data.\n",
            "---------------\n",
            "Model size = 256.\n",
            "ROUGE-1: 15.283 on test data.\n",
            "ROUGE-2: 3.960 on test data.\n",
            "ROUGE-l: 15.312 on test data.\n",
            "---------------\n",
            "Model size = 512.\n",
            "ROUGE-1: 15.399 on test data.\n",
            "ROUGE-2: 4.353 on test data.\n",
            "ROUGE-l: 15.385 on test data.\n",
            "---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZf6pN-dm6od",
        "colab_type": "text"
      },
      "source": [
        "## **3.2 SumGAN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9378RSJnRmN",
        "colab_type": "text"
      },
      "source": [
        "**Discriminator initialization**\n",
        "\n",
        "<hr>\n",
        "\n",
        "This step is required and it is an undesired artifact of our non-ideal implemntation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E133QKFVnROz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Model & Training specification #####\n",
        "param = {'max_epochs': 80,\n",
        "            'learning_rate': 5e-4,\n",
        "            'batch_size': 32,               \n",
        "            'seq_len': 68,                   # length of your summary\n",
        "            'embed_dim': 200,\n",
        "            'drop_out': 0.5,\n",
        "            'kernel_num': 50,                 # number of your feature map\n",
        "            'in_channel': 1,                 # for text classification should be one\n",
        "            # how many conv net are used in parallel in text classification\n",
        "            'parallel_layer': 3,\n",
        "            'model_name': 'n_{:.0f}_d_{:.0f}'.format(50, 10*0.5),\n",
        "            'device':'cuda'}\n",
        "##########################################\n",
        "\n",
        "\n",
        "# Initialization the model and load the state\n",
        "Discriminator = Discriminator_utility(pre_train_weight_head,**param)\n",
        "Discriminator.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx9mNLKNoz-S",
        "colab_type": "text"
      },
      "source": [
        "**GAN initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1LCYtN0ozue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61ad6797-d047-4b9d-cca9-2839e0894dcf"
      },
      "source": [
        "##### Model & Training specification #####\n",
        "grid = {'max_epochs': 2,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate_D': 5e-4,\n",
        "        'learning_rate_G': 1e-3,\n",
        "        'G_multiple': 2,\n",
        "        'l2_reg': 0.1,      # appled only for discriminator\n",
        "        'clip': 10,\n",
        "        'model_name': 'Adversarial_v02',\n",
        "        'text_dictionary': text_dictionary,\n",
        "        'headline_dictionary': headline_dictionary,\n",
        "        'device': 'cuda',\n",
        "        'noise_std': 0.00, \n",
        "        'optim_d_prob': 0.15 #this values determines the probability a discriminator will make step with\n",
        "        }\n",
        "\n",
        "##########################################\n",
        "\n",
        "\n",
        "# Initialization the model and load the state\n",
        "GAN = AdversarialTraining(Generator, Discriminator, optim.Adam, optim.SGD, **grid)\n",
        "GAN.load()  # if any"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No state has been loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxEcTkNKp02C",
        "colab_type": "text"
      },
      "source": [
        "**ROUGE**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDhsxq6gmcuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3c88c3d7-7e3c-4197-f486-2429a455c3de"
      },
      "source": [
        " ##### ROUGE scores #####\n",
        "  # Generate hypothesis and conver them into text\n",
        "  hypotheses = GAN.generate_summaries(text_test, text_lengths_test, headline_test, headline_lengths_test)\n",
        "  hypotheses = sum(\n",
        "      [[' '.join([headline_dictionary.index2word[index] for index in batch[:, hypothesis] if (index != pad_idx) & (index != eos_idx)][1:]) for hypothesis in range(batch.shape[1])] for batch in hypotheses], []\n",
        "  )\n",
        "  \n",
        "  # Convert references into the text\n",
        "  references = [' '.join([headline_dictionary.index2word[index] for index in headline_test[:, sentence] if (index != pad_idx) & (index != eos_idx)][1:]) for sentence in range(headline_test.shape[1])]\n",
        "  \n",
        "  # trim (only full batches are generated)\n",
        "  lim = Generator.n_batches * grid['batch_size']\n",
        "  references[:lim]\n",
        "\n",
        "  # Compute average rouge scores\n",
        "  rouge1 = [rouge_get_scores(hyp, ref, '1') for hyp, ref in zip(hypotheses, references)]\n",
        "  rouge1 = np.array([x for x in rouge1 if x != 'drop']).mean()\n",
        "  rouge2 = [rouge_get_scores(hyp, ref, '2') for hyp, ref in zip(hypotheses, references)]\n",
        "  rouge2 = np.array([x for x in rouge2 if x != 'drop']).mean()\n",
        "  rougel = [rouge_get_scores(hyp, ref, 'l') for hyp, ref in zip(hypotheses, references)]\n",
        "  rougel = np.array([x for x in rougel if x != 'drop']).mean()\n",
        "  \n",
        "  # cleaning\n",
        "  del hypotheses, references\n",
        "  gc.collect()\n",
        "\n",
        "  # Print rouge scores\n",
        "  print('Model size = {:.0f}.'.format(model_size))\n",
        "  print('ROUGE-1: {:.3f} on test data.'.format(100*np.array(rouge1)))\n",
        "  print('ROUGE-2: {:.3f} on test data.'.format(100*np.array(rouge2)))\n",
        "  print('ROUGE-l: {:.3f} on test data.'.format(100*np.array(rougel)))\n",
        "  print('---------------')\n",
        "\n",
        "  # Save results\n",
        "  ROUGE = {'ROUGE-1': rouge1,\n",
        "           'ROUGE-2': rouge2,\n",
        "           'ROUGE-L': rougel}\n",
        "  json_file = json.dumps(ROUGE)\n",
        "  file = open('Results/ROUGE_Adv02_test.txt'.format(model_size), \"w\")\n",
        "  file.write(json_file)\n",
        "  file.close()\n",
        "\n",
        "# Push everything to github\n",
        "#push_to_repo()#"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model size = 512.\n",
            "ROUGE-1: 19.382 on test data.\n",
            "ROUGE-2: 6.209 on test data.\n",
            "ROUGE-l: 19.343 on test data.\n",
            "---------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZt32f4JqMsJ",
        "colab_type": "text"
      },
      "source": [
        "## **3.3 Print out some generated summaries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbourzaVqwQF",
        "colab_type": "text"
      },
      "source": [
        "**Baseline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Z0v9viqTp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generator.load()\n",
        "\n",
        "hypotheses_2 = Generator.generate_summaries(text_test, text_lengths_test, headline_test, headline_lengths_test)\n",
        "hypotheses_2 = sum(\n",
        "    [[' '.join([headline_dictionary.index2word[index] for index in batch[:, hypothesis] if (index != pad_idx) & (index != eos_idx)][1:]) for hypothesis in range(batch.shape[1])] for batch in hypotheses_2], []\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHU3LhEXq31V",
        "colab_type": "text"
      },
      "source": [
        "**SumGAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1QXGxXRq3qB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d258e33-6ebd-46cf-8ea1-323a9664b523"
      },
      "source": [
        "GAN.load()\n",
        "\n",
        "hypotheses_1 = GAN.generate_summaries(text_test, text_lengths_test, headline_test, headline_lengths_test)\n",
        "hypotheses_1 = sum(\n",
        "    [[' '.join([headline_dictionary.index2word[index] for index in batch[:, hypothesis] if (index != pad_idx) & (index != eos_idx)][1:]) for hypothesis in range(batch.shape[1])] for batch in hypotheses_1], []\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No state has been loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8clYhjdgq-FK",
        "colab_type": "text"
      },
      "source": [
        "**Take reference headlines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mep59Aygq-6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "references = [' '.join([headline_dictionary.index2word[index] for index in headline_test[:, sentence] if (index != pad_idx) & (index != eos_idx)][1:]) for sentence in range(headline_test.shape[1])]\n",
        "# trim\n",
        "n_batches = len(references) // grid['batch_size']\n",
        "lim = n_batches * grid['batch_size']\n",
        "references = references[:lim]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7021moxfrGKK",
        "colab_type": "text"
      },
      "source": [
        "**Print random sample**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOXHDmRirGcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60cc330c-f0c2-4e56-bf71-64da7032c3eb"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Take a random sample\n",
        "samples = np.random.choice(lim, 50, replace = False)\n",
        "hypotheses_1, hypotheses_2, references = (\n",
        "    np.array(hypotheses_1)[samples],\n",
        "    np.array(hypotheses_2)[samples],\n",
        "    np.array(references)[samples]\n",
        ")\n",
        "\n",
        "# Print and save\n",
        "for hyp_1, hyp_2, ref in zip(\n",
        "    hypotheses_1,\n",
        "    hypotheses_2,\n",
        "    references):\n",
        "  print(f'Reference: {ref}')\n",
        "  print(colored(f'Baseline: {hyp_2}', 'blue'))\n",
        "  print(colored(f'SumGAN: {hyp_1}', 'green')) \n",
        "  print('----------')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reference: rely on friends and family .\n",
            "\u001b[34mBaseline: be positive .\u001b[0m\n",
            "\u001b[32mSumGAN: ask for help .\u001b[0m\n",
            "----------\n",
            "Reference: fuel your body with nutritious foods .\n",
            "\u001b[34mBaseline: eat a healthy diet .\u001b[0m\n",
            "\u001b[32mSumGAN: eat a healthy diet .\u001b[0m\n",
            "----------\n",
            "Reference: have your vet trim your guinea pigs nails .\n",
            "\u001b[34mBaseline: get your guinea pig .\u001b[0m\n",
            "\u001b[32mSumGAN: get your guinea pig .\u001b[0m\n",
            "----------\n",
            "Reference: use washable bedding on the bed .\n",
            "\u001b[34mBaseline: clean your bedding .\u001b[0m\n",
            "\u001b[32mSumGAN: clean your bedding .\u001b[0m\n",
            "----------\n",
            "Reference: get a good night s rest .\n",
            "\u001b[34mBaseline: get plenty of sleep .\u001b[0m\n",
            "\u001b[32mSumGAN: get enough sleep .\u001b[0m\n",
            "----------\n",
            "Reference: consider your family wishes and lifestyle .\n",
            "\u001b[34mBaseline: be aware of your family .\u001b[0m\n",
            "\u001b[32mSumGAN: consider your family history .\u001b[0m\n",
            "----------\n",
            "Reference: add additional front matter .\n",
            "\u001b[34mBaseline: write your first draft .\u001b[0m\n",
            "\u001b[32mSumGAN: write a brief .\u001b[0m\n",
            "----------\n",
            "Reference: use ice for injuries .\n",
            "\u001b[34mBaseline: ice your ice .\u001b[0m\n",
            "\u001b[32mSumGAN: ice your ice .\u001b[0m\n",
            "----------\n",
            "Reference: spend time with people who support your recovery .\n",
            "\u001b[34mBaseline: join your support .\u001b[0m\n",
            "\u001b[32mSumGAN: join a support group .\u001b[0m\n",
            "----------\n",
            "Reference: look for severe swelling around your thumb .\n",
            "\u001b[34mBaseline: continue your fingers .\u001b[0m\n",
            "\u001b[32mSumGAN: continue your fingers .\u001b[0m\n",
            "----------\n",
            "Reference: get involved on campus .\n",
            "\u001b[34mBaseline: join a share .\u001b[0m\n",
            "\u001b[32mSumGAN: join a local community .\u001b[0m\n",
            "----------\n",
            "Reference: keep a notepad handy .\n",
            "\u001b[34mBaseline: keep a journal .\u001b[0m\n",
            "\u001b[32mSumGAN: write down your thoughts .\u001b[0m\n",
            "----------\n",
            "Reference: keep a journal of your mistakes and successes .\n",
            "\u001b[34mBaseline: keep a journal .\u001b[0m\n",
            "\u001b[32mSumGAN: write down your goals .\u001b[0m\n",
            "----------\n",
            "Reference: talk about yourself too .\n",
            "\u001b[34mBaseline: talk to your friend .\u001b[0m\n",
            "\u001b[32mSumGAN: talk to your friend about your friends .\u001b[0m\n",
            "----------\n",
            "Reference: practice .\n",
            "\u001b[34mBaseline: keep your mind .\u001b[0m\n",
            "\u001b[32mSumGAN: practice your speech .\u001b[0m\n",
            "----------\n",
            "Reference: start with one outdoor run a week .\n",
            "\u001b[34mBaseline: run your workout .\u001b[0m\n",
            "\u001b[32mSumGAN: run a workout .\u001b[0m\n",
            "----------\n",
            "Reference: view all logs recorded by your fitbit tracker .\n",
            "\u001b[34mBaseline: click the app .\u001b[0m\n",
            "\u001b[32mSumGAN: choose the right side .\u001b[0m\n",
            "----------\n",
            "Reference: research local laws .\n",
            "\u001b[34mBaseline: avoid share .\u001b[0m\n",
            "\u001b[32mSumGAN: check the laws .\u001b[0m\n",
            "----------\n",
            "Reference: use the self evaluation as an opportunity .\n",
            "\u001b[34mBaseline: be patient .\u001b[0m\n",
            "\u001b[32mSumGAN: identify the purpose of your job .\u001b[0m\n",
            "----------\n",
            "Reference: use an ice cube or a cool wet compress .\n",
            "\u001b[34mBaseline: apply a ice compress .\u001b[0m\n",
            "\u001b[32mSumGAN: apply a cold compress .\u001b[0m\n",
            "----------\n",
            "Reference: adopt good habits .\n",
            "\u001b[34mBaseline: avoid eating .\u001b[0m\n",
            "\u001b[32mSumGAN: avoid eating habits .\u001b[0m\n",
            "----------\n",
            "Reference: identify common early symptoms .\n",
            "\u001b[34mBaseline: recognize the symptoms .\u001b[0m\n",
            "\u001b[32mSumGAN: recognize the symptoms of symptoms .\u001b[0m\n",
            "----------\n",
            "Reference: determine what the nursing school is looking for from your personal statement .\n",
            "\u001b[34mBaseline: follow the instructions .\u001b[0m\n",
            "\u001b[32mSumGAN: follow the instructions s instructions .\u001b[0m\n",
            "----------\n",
            "Reference: attend parent management training programs and family therapy .while you may have found it less difficult to handle your other children and their problems you may find yourself at a loss in how to parent your child with odd .\n",
            "\u001b[34mBaseline: learn about your options .\u001b[0m\n",
            "\u001b[32mSumGAN: learn a new class .\u001b[0m\n",
            "----------\n",
            "Reference: take deep steady breaths .\n",
            "\u001b[34mBaseline: take a deep breath .\u001b[0m\n",
            "\u001b[32mSumGAN: take a deep breath .\u001b[0m\n",
            "----------\n",
            "Reference: keep a chair at arms length in front of you .\n",
            "\u001b[34mBaseline: get a good position .\u001b[0m\n",
            "\u001b[32mSumGAN: get a good posture .\u001b[0m\n",
            "----------\n",
            "Reference: practice safe sex .\n",
            "\u001b[34mBaseline: avoid using your condom .\u001b[0m\n",
            "\u001b[32mSumGAN: avoid using sex .\u001b[0m\n",
            "----------\n",
            "Reference: inquire about long term prognosis .\n",
            "\u001b[34mBaseline: apply a prescription .\u001b[0m\n",
            "\u001b[32mSumGAN: consider your dentist .\u001b[0m\n",
            "----------\n",
            "Reference: strengthen your relationships with other people .\n",
            "\u001b[34mBaseline: be happy .\u001b[0m\n",
            "\u001b[32mSumGAN: think about what you want to do .\u001b[0m\n",
            "----------\n",
            "Reference: revise and format the article .\n",
            "\u001b[34mBaseline: type the article .\u001b[0m\n",
            "\u001b[32mSumGAN: write the article .\u001b[0m\n",
            "----------\n",
            "Reference: try singing .\n",
            "\u001b[34mBaseline: enjoy your child .\u001b[0m\n",
            "\u001b[32mSumGAN: listen to your baby .\u001b[0m\n",
            "----------\n",
            "Reference: choose a suitable target .\n",
            "\u001b[34mBaseline: choose a share .\u001b[0m\n",
            "\u001b[32mSumGAN: choose a share .\u001b[0m\n",
            "----------\n",
            "Reference: strap the cage down .\n",
            "\u001b[34mBaseline: wear a comfortable cage .\u001b[0m\n",
            "\u001b[32mSumGAN: use a share or share .\u001b[0m\n",
            "----------\n",
            "Reference: pay attention to share relationships .\n",
            "\u001b[34mBaseline: create a share .\u001b[0m\n",
            "\u001b[32mSumGAN: write down the share .\u001b[0m\n",
            "----------\n",
            "Reference: stay in a cool room .\n",
            "\u001b[34mBaseline: turn on the air .\u001b[0m\n",
            "\u001b[32mSumGAN: keep the air cool .\u001b[0m\n",
            "----------\n",
            "Reference: consider other immune boosting supplements .\n",
            "\u001b[34mBaseline: take vitamin c .\u001b[0m\n",
            "\u001b[32mSumGAN: take vitamin c . vitamin c is a day .\u001b[0m\n",
            "----------\n",
            "Reference: add your contact information .\n",
            "\u001b[34mBaseline: type the name of the page .\u001b[0m\n",
            "\u001b[32mSumGAN: address the letter .\u001b[0m\n",
            "----------\n",
            "Reference: spend time with friends .\n",
            "\u001b[34mBaseline: enjoy your friends .\u001b[0m\n",
            "\u001b[32mSumGAN: join a support group .\u001b[0m\n",
            "----------\n",
            "Reference: receive confirmation of processing .\n",
            "\u001b[34mBaseline: submit your application .\u001b[0m\n",
            "\u001b[32mSumGAN: submit your application .\u001b[0m\n",
            "----------\n",
            "Reference: aim for the sweet spot on the backboard .\n",
            "\u001b[34mBaseline: turn the ball .\u001b[0m\n",
            "\u001b[32mSumGAN: place the ball in the ball .\u001b[0m\n",
            "----------\n",
            "Reference: begin by building one room .\n",
            "\u001b[34mBaseline: take a quiet .\u001b[0m\n",
            "\u001b[32mSumGAN: take a quiet place .\u001b[0m\n",
            "----------\n",
            "Reference: talk about strengths .\n",
            "\u001b[34mBaseline: be confident .\u001b[0m\n",
            "\u001b[32mSumGAN: talk to your team .\u001b[0m\n",
            "----------\n",
            "Reference: address your partners fears .\n",
            "\u001b[34mBaseline: continue to be patient .\u001b[0m\n",
            "\u001b[32mSumGAN: address your partner .\u001b[0m\n",
            "----------\n",
            "Reference: know how infection is transmitted .\n",
            "\u001b[34mBaseline: avoid alcohol .\u001b[0m\n",
            "\u001b[32mSumGAN: avoid certain and fluids .\u001b[0m\n",
            "----------\n",
            "Reference: limit sun exposure .\n",
            "\u001b[34mBaseline: avoid using the share .\u001b[0m\n",
            "\u001b[32mSumGAN: avoid using the skin .\u001b[0m\n",
            "----------\n",
            "Reference: try the two share method .\n",
            "\u001b[34mBaseline: drink water .\u001b[0m\n",
            "\u001b[32mSumGAN: drink a glass of water .\u001b[0m\n",
            "----------\n",
            "Reference: visit the dentist regularly .\n",
            "\u001b[34mBaseline: visit your dentist .\u001b[0m\n",
            "\u001b[32mSumGAN: visit your dentist .\u001b[0m\n",
            "----------\n",
            "Reference: contact your doctor if symptoms do not go away quickly .\n",
            "\u001b[34mBaseline: drink plenty of water .\u001b[0m\n",
            "\u001b[32mSumGAN: see your doctor .\u001b[0m\n",
            "----------\n",
            "Reference: specify which pages the article appears on .\n",
            "\u001b[34mBaseline: type the page of the article .\u001b[0m\n",
            "\u001b[32mSumGAN: cite the page numbers .\u001b[0m\n",
            "----------\n",
            "Reference: provide share clues .\n",
            "\u001b[34mBaseline: create a story .\u001b[0m\n",
            "\u001b[32mSumGAN: make a list of your story .\u001b[0m\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsXnHQwvrJ8N",
        "colab_type": "text"
      },
      "source": [
        "**Save**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCsqsf_lrJvK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "68065c97-30ab-4d33-fc07-cdd479281ea3"
      },
      "source": [
        "# Save to txt\n",
        "np.savetxt(\n",
        "    r'Results/samples_summaries.txt',\n",
        "    np.array([references, hypotheses_1, hypotheses_2]),\n",
        "    fmt = '%s'\n",
        ")\n",
        "\n",
        "# push to repo\n",
        "push_to_repo()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: No such remote: origin\n",
            "/bin/bash: your_username: No such file or directory\n",
            "M\tResults/samples_summaries.txt\n",
            "Already on 'master'\n",
            "fatal: 'origin' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n",
            "error: pathspec 'models_branch' did not match any file(s) known to git.\n",
            "[master c4f9e4d] model state update\n",
            " 2 files changed, 4 insertions(+), 3 deletions(-)\n",
            " create mode 100644 Results/ROUGE_Adv02_test.txt\n",
            " rewrite Results/samples_summaries.txt (100%)\n",
            "Already on 'master'\n",
            "merge: models_branch - not something we can merge\n",
            "fatal: 'origin' does not appear to be a git repository\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}