{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANs for Abstractive Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ult0blXNbHtv",
        "colab_type": "text"
      },
      "source": [
        "**Function keeping Colab running**\n",
        "\n",
        "<hr>\n",
        "\n",
        "1. Ctrl + Shift + I\n",
        "2. Put the code below into the console"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70kWNWiMbHdG",
        "colab_type": "code",
        "outputId": "145478a1-b771-46dd-88a2-1fb4cb70ac64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nfunction ClickConnect(){\\n    console.log(\"Clicked on connect button\"); \\n    document.querySelector(\"colab-connect-button\").click()\\n}\\nsetInterval(ClickConnect,60000)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIyt-AKk1biq",
        "colab_type": "text"
      },
      "source": [
        "# **GANs for Abstractive Text Summarization**\n",
        "## **NLP Group Project**\n",
        "## **Statistical Natural Language Processing (COMP0087), University College London**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Project description**\n",
        "\n",
        "A lot of endeavours have already been devoted to NLP text summarization techniques, and abstractive methods have proved to be more proficient in generating human-like sentences. At the same time, GANs has been enjoying considerable success in the area of real-valued data such as an image generation. Recently, researchers have begun to come up with ideas on how to overcome various obstacles during training GAN models for discrete data, though not a lot of work seemed to be directly dedicated to the text summarization itself. We, therefore, would like to pursue to tackle the issue of text summarization using the GAN techniques inspired by sources enlisted below.\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Collaborators**\n",
        "\n",
        "- Daniel Stancl (daniel.stancl.19@ucl.ac.uk)\n",
        "- Dorota Jagnesakova (dorota.jagnesakova.19@ucl.ac.uk)\n",
        "- Guolinag HE (guoliang.he.19@ucl.ac.uk)\n",
        "- Zakhar Borok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzNR-0NJoCOV",
        "colab_type": "text"
      },
      "source": [
        "# **1 Setup**\n",
        "\n",
        "<hr>\n",
        "\n",
        "- install and import libraries\n",
        "- download stopwords\n",
        "- remove and clone the most recent version of git repository\n",
        "- run a script with a CONTRACTION_MAP\n",
        "- run a script with a function for text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRRMxZxggWVl",
        "colab_type": "text"
      },
      "source": [
        "### **GitHub stuff**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkaEqWkNphsX",
        "colab_type": "text"
      },
      "source": [
        "**Set GitHub credentials and username of repo owner**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0r58gXnphct",
        "colab_type": "code",
        "outputId": "c7e6e885-321d-468e-e8cc-cf0619c5fb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# credentials\n",
        "user_email = 'dannyi@seznam.cz'\n",
        "user = \"gansforlife\"\n",
        "user_password = \"dankodorkamichaelzak\"\n",
        "\n",
        "# username of repo owner\n",
        "owner_username = 'stancld'\n",
        "# reponame\n",
        "reponame = 'GeneratingHeadline_GANs'\n",
        "\n",
        "# generate \n",
        "add_origin_link = (\n",
        "    'https://{}:{}github@github.com/{}/{}.git'.format(\n",
        "    user, user_password, owner_username, reponame)\n",
        ")\n",
        "\n",
        "print(\"Link used for git cooperation:\\n{}\".format(add_origin_link))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Link used for git cooperation:\n",
            "https://gansforlife:dankodorkamichaelzakgithub@github.com/stancld/GeneratingHeadline_GANs.git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izq91t63kr2l",
        "colab_type": "text"
      },
      "source": [
        "**Clone GitHub repo on the personal drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va3lSdh1ycMI",
        "colab_type": "code",
        "outputId": "c9ee671f-044c-4a36-bb6c-2c844057a132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Clone GitHub repo to the desired folder\n",
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "%cd \"drive/My Drive/projects\"\n",
        "\n",
        "# Remove NLP_Project if presented and clone up-to-date repo\n",
        "!rm -r GeneratingHeadline_GANs\n",
        "!git clone https://github.com/stancld/GeneratingHeadline_GANs.git\n",
        "\n",
        "# Go to the NLP_Project folder\n",
        "%cd GeneratingHeadline_GANs\n",
        "\n",
        "# Config global user and add origin enabling us to execute push commands\n",
        "!git config --global user.email user_email\n",
        "!git remote rm origin\n",
        "!git remote add origin https://gansforlife:dankodorkamichaelzakgithub@github.com/stancld/GeneratingHeadline_GANs.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/projects\n",
            "Cloning into 'GeneratingHeadline_GANs'...\n",
            "remote: Enumerating objects: 377, done.\u001b[K\n",
            "remote: Counting objects: 100% (377/377), done.\u001b[K\n",
            "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
            "remote: Total 377 (delta 161), reused 294 (delta 78), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (377/377), 16.66 MiB | 19.06 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n",
            "/content/drive/My Drive/projects/GeneratingHeadline_GANs\n",
            "CPU times: user 210 ms, sys: 85.7 ms, total: 295 ms\n",
            "Wall time: 9.49 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtd82jejgjsJ",
        "colab_type": "text"
      },
      "source": [
        "**Function push_to_repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQKbDCp2gZs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def push_to_repo():\n",
        "  \"\"\"\n",
        "  models_branch\n",
        "  \"\"\"\n",
        "  !git remote rm origin\n",
        "  !git remote add origin https://gansforlife:dankodorkamichaelzak@github.com/stancld/GeneratingHeadline_GANs.git\n",
        "  !git checkout master\n",
        "  !git pull origin master\n",
        "  !git checkout models_branch\n",
        "  !git add .\n",
        "  !git commit -m \"model state update\"\n",
        "  !git checkout master\n",
        "  !git merge models_branch\n",
        "  !git push -u origin master"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSITDO2N88Mu",
        "colab_type": "text"
      },
      "source": [
        "### **General stuff**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQViomvJmmxy",
        "colab_type": "text"
      },
      "source": [
        "**Import essential libraries and load necessary conditionalities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfSL4JZGoXH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import gc\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9EI-8lbFAfk",
        "colab_type": "code",
        "outputId": "3399d9cd-7156-4271-a12b-b840202db55a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9csn_FoXmqMR",
        "colab_type": "text"
      },
      "source": [
        "**Set essential parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpfj2zejmsaV",
        "colab_type": "code",
        "outputId": "b45e1da2-b611-446d-9d0a-238c805531bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Set torch.device to use GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJyjpXDMo-HN",
        "colab_type": "text"
      },
      "source": [
        "**Run python files from with classes used throughtout the document**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhIgA7osp7Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run Code/contractions.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb3DjRcT1gm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for text_preprocessing()\n",
        "run Code/text_preprocessing.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ0x45Yzqggm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for transforming data to padded array\n",
        "run Code/data2PaddedArray.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBm-0p9IS9yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the baseline model class _Seq2Seq()\n",
        "run Code/Models/Attention_seq2seq.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrL0zprqccwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code for the training class\n",
        "run Code/Models/generator_training_class.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZMHJLms80hC",
        "colab_type": "text"
      },
      "source": [
        "### **Pretrained embeddings**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**TODO:** *Put a comment which kind of embeddings we used. Add some references and so on*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfPzKeHh80DB",
        "colab_type": "code",
        "outputId": "71842936-3ef5-44e1-e719-28f58a054faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embed_dim = 200\n",
        "\n",
        "# Download and unzip GloVe embedding\n",
        "#!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "#!unzip glove.6B.zip\n",
        "\n",
        "\n",
        "# input your pre-train txt path and parse the data\n",
        "#path = '../data/glove.6B.100d.txt'\n",
        "path = '../data/glove.6B.{:.0f}d.txt'.format(embed_dim)\n",
        "embed_dict = {}\n",
        "with open(path,'r') as f:\n",
        "  lines = f.readlines()\n",
        "  for l in lines:\n",
        "    w = l.split()[0]\n",
        "    v = np.array(l.split()[1:]).astype('float')\n",
        "    embed_dict[w] = v\n",
        "\n",
        "embed_dict['@@_unknown_@@'] = np.random.random(embed_dim) # if we use 100 dimension embeddings\n",
        "\n",
        "# remove all the unnecesary files\n",
        "#!rm -rf glove.6B.zip\n",
        "#!rm -rf glove.6B.50d.txt\n",
        "#!rm -rf glove.6B.100d.txt\n",
        "#!rm -rf glove.6B.200d.txt\n",
        "#!rm -rf glove.6B.300d.txt\n",
        "\n",
        "# check the length of the dictionary\n",
        "len(embed_dict.keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_doqN6K-L_f",
        "colab_type": "text"
      },
      "source": [
        "**Function for extracting relevant matrix of pretrained weights** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwSHzoth-LmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_weight(text_dictionary):\n",
        "  \"\"\"\n",
        "  :param text_dictionary:\n",
        "  \"\"\"\n",
        "  pre_train_weight = []\n",
        "  for word_index in text_dictionary.index2word.keys():\n",
        "    if word_index != 0:\n",
        "      word = text_dictionary.index2word[word_index]\n",
        "      try:\n",
        "        word_vector = embed_dict[word].reshape(1,-1)\n",
        "      except:\n",
        "        word_vector = embed_dict['@@_unknown_@@'].reshape(1,-1) # handle unknown word\n",
        "      pre_train_weight = np.vstack([pre_train_weight,word_vector])\n",
        "    \n",
        "    # add for padding\n",
        "    elif word_index == len(text_dictionary.index2word.keys()):  \n",
        "      pre_train_weight = np.r_[pre_train_weight, np.zeros((1, embed_dim))]\n",
        "    \n",
        "    else:\n",
        "      word = text_dictionary.index2word[word_index]\n",
        "      try:\n",
        "        word_vector = embed_dict[word].reshape(1,-1)\n",
        "      except:\n",
        "        word_vector = embed_dict['@@_unknown_@@'].reshape(1,-1) # handle unknown word\n",
        "      pre_train_weight = word_vector\n",
        "  return pre_train_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25PaDFvYp8VY",
        "colab_type": "text"
      },
      "source": [
        "# **2 Load and process the data**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Source of the data:** https://ucsb.app.box.com/s/7yq601ijl1lzvlfu4rjdbbxforzd2oag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1AQ45P8lRzX",
        "colab_type": "text"
      },
      "source": [
        "##### *Download and open data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRY-oCuJLC-u",
        "colab_type": "code",
        "outputId": "e920a21a-0fd4-4cfb-f574-bfeb22c7d189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "data = pd.read_csv('../data/wikihowSep.csv',\n",
        "                   error_bad_lines = False).astype(str)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1585695, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK8sAfrOlXlG",
        "colab_type": "text"
      },
      "source": [
        "##### *Pre-process data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Mhr5-d1aqx",
        "colab_type": "code",
        "outputId": "9709df17-10d3-472d-ef21-7ac9090939ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%time\n",
        "\n",
        "for item in ['text', 'headline']:\n",
        "  exec(\"\"\"{}_data = text_preprocessing(data=data, item = '{}', contraction_map=CONTRACTION_MAP,\n",
        "                                  drop_digits=False, remove_stopwords=False, stemming=False)\"\"\".format(item, item),\n",
        "       locals(), globals()\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.96 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn-AsxLZVvOD",
        "colab_type": "text"
      },
      "source": [
        "##### *Clean flawed examples*\n",
        "\n",
        "<hr>\n",
        "\n",
        "- drop examples based on the threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw5hZUiJKIW4",
        "colab_type": "code",
        "outputId": "04c4b012-ad8a-4942-8312-fa9bdf6e8f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "# drop examples with an invalid ratio of length of text and headline\n",
        "text_len = [len(t) for t in text_data]\n",
        "head_len = [len(h) for h in headline_data]\n",
        "\n",
        "print('Some statistics')\n",
        "\n",
        "print('Average length of articles is {:.2f}.'.format(np.array(text_len).mean()))\n",
        "print('Min = {:.0f}, Max = {:.0f}, Std = {:.2f}'.format(min(text_len), max(text_len), np.array(text_len).std()))\n",
        "\n",
        "print('-----')\n",
        "\n",
        "print('Average length of summaries is {:.2f}.'.format(np.array(head_len).mean()))\n",
        "print('Min = {:.0f}, Max = {:.0f}, Std = {:.2f}'.format(min(head_len), max(head_len), np.array(head_len).std()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some statistics\n",
            "Average length of articles is 90.06.\n",
            "Min = 2, Max = 1660, Std = 59.56\n",
            "-----\n",
            "Average length of summaries is 10.29.\n",
            "Min = 2, Max = 226, Std = 6.45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKyHNUTrWNvL",
        "colab_type": "code",
        "outputId": "f3104a1f-dea4-4217-953c-dcff8fff4a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "max_examples = 150000\n",
        "max_threshold = 0.75\n",
        "\n",
        "# drop examples with an invalid ratio of length of text and headline\n",
        "text_len = [len(t) for t in text_data]\n",
        "head_len = [len(h) for h in headline_data]\n",
        "\n",
        "ratio = [h/t for t, h in zip(text_len, head_len)]\n",
        "\n",
        "problems1 = [problem for problem, r in enumerate(ratio) if (r > max_threshold)]\n",
        "text_data, headline_data = np.delete(text_data, problems1), np.delete(headline_data, problems1)\n",
        "print(\"Number of examples after filtering: {:.0f}\".format(text_data.shape[0]))\n",
        "\n",
        "# drop too long articles (to avoid struggles with CUDA memory) and too short\n",
        "text_len = [len(t) for t in text_data]\n",
        "\n",
        "problems2 = [problem for problem, text_length in enumerate(text_len) if ((text_length > 200) | (text_length < 10) )]\n",
        "text_data, headline_data = np.delete(text_data, problems2), np.delete(headline_data, problems2)\n",
        "print(\"Number of examples after filtering: {:.0f}\".format(text_data.shape[0]))\n",
        "\n",
        "# drop too pairs with too short/long summaries\n",
        "head_len = [len(h) for h in headline_data]\n",
        "\n",
        "problems3 = [problem for problem, headline_len in enumerate(head_len) if ( (headline_len > 75) | (headline_len < 2) )]\n",
        "text_data, headline_data = np.delete(text_data, problems3), np.delete(headline_data, problems3)\n",
        "print(\"Number of examples after filtering: {:.0f}\".format(text_data.shape[0]))\n",
        "\n",
        "# some cleaning\n",
        "del text_len, head_len, ratio, problems1, problems2, problems3\n",
        "gc.collect()\n",
        "\n",
        "\"\"\"\n",
        "# trim the data to have only a subset of the data for our project\n",
        "try:\n",
        "  data = data[:max_examples]\n",
        "except:\n",
        "  pass\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples after filtering: 138821\n",
            "Number of examples after filtering: 132047\n",
            "Number of examples after filtering: 132041\n",
            "(150000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KKBqq0oIgey",
        "colab_type": "text"
      },
      "source": [
        "*Print some statistics*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKHJ_IiUIf8I",
        "colab_type": "code",
        "outputId": "a085f71d-7158-4826-e602-21f3d57296c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "# drop examples with an invalid ratio of length of text and headline\n",
        "text_len = [len(t) for t in text_data]\n",
        "head_len = [len(h) for h in headline_data]\n",
        "\n",
        "print('Some statistics')\n",
        "\n",
        "print('Average length of articles is {:.2f}.'.format(np.array(text_len).mean()))\n",
        "print('Min = {:.0f}, Max = {:.0f}, Std = {:.2f}'.format(min(text_len), max(text_len), np.array(text_len).std()))\n",
        "\n",
        "print('-----')\n",
        "\n",
        "print('Average length of summaries is {:.2f}.'.format(np.array(head_len).mean()))\n",
        "print('Min = {:.0f}, Max = {:.0f}, Std = {:.2f}'.format(min(head_len), max(head_len), np.array(head_len).std()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some statistics\n",
            "Average length of articles is 88.48.\n",
            "Min = 10, Max = 200, Std = 42.77\n",
            "-----\n",
            "Average length of summaries is 9.41.\n",
            "Min = 3, Max = 68, Std = 4.53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBkI74Qa9Y9v",
        "colab_type": "text"
      },
      "source": [
        "##### *Split data into train/val/test set*\n",
        "\n",
        "<hr>\n",
        "\n",
        "It's crucial to do this split in this step so that a dictionary that will be created for our model won't contain any words from validation/test set which are not presented in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsXTsEEV8851",
        "colab_type": "code",
        "outputId": "7ea505f7-2c10-48a5-8e9c-30952e6bcc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "np.random.seed(222)\n",
        "\n",
        "split = np.random.uniform(0, 1, size = text_data.shape[0])\n",
        "\n",
        "# Train set\n",
        "text_train, headline_train = text_data[split <= 0.9], headline_data[split <= 0.9]\n",
        "# Validation set\n",
        "text_val, headline_val = text_data[(split > 0.9) & (split <= 0.95)], headline_data[(split > 0.9) & (split <= 0.95)]\n",
        "# Test set\n",
        "text_test, headline_test = text_data[split > 0.95], headline_data[split > 0.95]\n",
        "\n",
        "del data\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a14LfijYE6bP",
        "colab_type": "text"
      },
      "source": [
        "*Print some statistics*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HGCRWtBE5r_",
        "colab_type": "code",
        "outputId": "26019e9a-87ef-4c64-ae58-d08b777d64db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Average lengths of articles is {:.2f}'.format(np.array([len(text) for text in text_train]).mean()))\n",
        "\n",
        "print('Average lengths of sumaries is {:.2f}'.format(np.array([len(text) for text in headline_train]).mean()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average lengths of articles is 88.41\n",
            "Average lengths of sumaries is 9.40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0nqBWooWsRv",
        "colab_type": "text"
      },
      "source": [
        "##### *Sort dataset from the longest sequence to the shortest one*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4tHv5huWss9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_data(text, headline):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  headline = np.array(\n",
        "      [y for x,y in sorted(zip(text, headline), key = lambda pair: len(pair[0]), reverse = True)]\n",
        "  )\n",
        "  text = list(text)\n",
        "  text.sort(key = lambda x: len(x), reverse = True)\n",
        "  text = np.array(text)\n",
        "\n",
        "  return text, headline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olWbPN8eY8j9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set\n",
        "text_train, headline_train = sort_data(text_train, headline_train)\n",
        "# Validation set\n",
        "text_val, headline_val = sort_data(text_val, headline_val)\n",
        "# Test set\n",
        "text_test, headline_test = sort_data(text_test, headline_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TLaKPwlFHdu",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare dictionary and embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dfcRmfIN5Yc",
        "colab_type": "text"
      },
      "source": [
        "##### *Create a dictionary and prepare a digestible representation of the data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbH1F24FOOhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LangDict:\n",
        "  \"\"\"\n",
        "  Source: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    self.word2index = {}\n",
        "    self.word2count = {}\n",
        "    self.index2word = {0: \"sos\", 1: \"eos\"}\n",
        "    self.n_words = 2\n",
        "\n",
        "  def add_article(self, article):\n",
        "    for word in article:\n",
        "      self.add_word(word)\n",
        "\n",
        "  def add_word(self, word):\n",
        "    if word not in self.word2index:\n",
        "      self.word2index[word] = self.n_words\n",
        "      self.word2count[word] = 1\n",
        "      self.index2word[self.n_words] = word\n",
        "      self.n_words += 1\n",
        "    else:\n",
        "      self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p5hFIFLQz_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionary based on the training data\n",
        "text_dictionary = LangDict()\n",
        "headline_dictionary = LangDict()\n",
        "\n",
        "for article in text_train:\n",
        "  text_dictionary.add_article(article)\n",
        "\n",
        "for article in headline_train:\n",
        "  headline_dictionary.add_article(article)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IULBuowRDHM",
        "colab_type": "code",
        "outputId": "33d016a9-dfbc-4ba9-df0f-6a55853ed292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "print(\"There are {:.0f} distinct words in the untrimmed text dictionary\".format(len(text_dictionary.word2index.keys())))\n",
        "print(\"There are {:.0f} distinct words in the untrimmed headline dictionary\".format(len(headline_dictionary.word2index.keys())))\n",
        "\n",
        "# Trim a dictionary to the words with at least 10 occurences within the text\n",
        "text_min_count = 1\n",
        "head_min_count = 2\n",
        "\n",
        "## TEXT DICTIONARY\n",
        "subset_words = [word for (word, count) in text_dictionary.word2count.items() if count >= text_min_count]\n",
        "text_dictionary.word2index = {word: i for (word, i) in zip(subset_words, range(len(subset_words)))}\n",
        "text_dictionary.index2word = {i: word for (word, i) in zip(subset_words, range(len(subset_words)))}\n",
        "text_dictionary.word2count = {word: count for (word, count) in text_dictionary.word2count.items() if count >= text_min_count}\n",
        "\n",
        "## HEADLINE DICTIONARY\n",
        "subset_words = [word for (word, count) in headline_dictionary.word2count.items() if count >= head_min_count]\n",
        "headline_dictionary.word2index = {word: i for (word, i) in zip(subset_words, range(len(subset_words)))}\n",
        "headline_dictionary.index2word = {i: word for (word, i) in zip(subset_words, range(len(subset_words)))}\n",
        "headline_dictionary.word2count = {word: count for (word, count) in headline_dictionary.word2count.items() if count >= head_min_count}\n",
        "\n",
        "print(\"There are {:.0f} distinct words in the trimmed text dictionary, where only word with at least {:.0f} occurences are retained\".format(len(text_dictionary.word2index.keys()), text_min_count))\n",
        "print(\"There are {:.0f} distinct words in the trimmed headline dictionary, where only word with at least {:.0f} occurences are retained\".format(len(headline_dictionary.word2index.keys()), head_min_count))\n",
        "del text_min_count, head_min_count, subset_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 62271 distinct words in the untrimmed text dictionary\n",
            "There are 21634 distinct words in the untrimmed headline dictionary\n",
            "There are 62271 distinct words in the trimmed text dictionary, where only word with at least 1 occurences are retained\n",
            "There are 13930 distinct words in the trimmed headline dictionary, where only word with at least 2 occurences are retained\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "992ZzrRcoK7d",
        "colab_type": "text"
      },
      "source": [
        "*Add pad token*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_TTnlQ5oKl2",
        "colab_type": "code",
        "outputId": "bdee0275-d719-4f96-9cad-db5057cd3a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "## TEXT DICTIONARY\n",
        "pad_idx = max(list(text_dictionary.index2word.keys())) + 1\n",
        "\n",
        "text_dictionary.word2index['<pad>'] = pad_idx\n",
        "text_dictionary.index2word[pad_idx] = '<pad>'\n",
        "\n",
        "print(len(text_dictionary.index2word.keys()))\n",
        "\n",
        "## HEADLINE DICTIONARY\n",
        "pad_idx = max(list(headline_dictionary.index2word.keys())) + 1\n",
        "\n",
        "headline_dictionary.word2index['<pad>'] = pad_idx\n",
        "headline_dictionary.index2word[pad_idx] = '<pad>'\n",
        "\n",
        "print(len(headline_dictionary.index2word.keys()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62272\n",
            "13931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGQcSyqKHF5l",
        "colab_type": "text"
      },
      "source": [
        "##### *Extract embedding vectors for words we need*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iTKyHy0lQvw",
        "colab_type": "code",
        "outputId": "f42e6fc3-8bf5-4149-c441-fd0e4a6114b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "pre_train_weight = extract_weight(text_dictionary)\n",
        "pre_train_weight = np.array(pre_train_weight, dtype = np.float32)\n",
        "\n",
        "del embed_dictl\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11min 29s, sys: 32.5 s, total: 12min 2s\n",
            "Wall time: 12min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHL6SrbtjSZX",
        "colab_type": "text"
      },
      "source": [
        "### **Transform the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONMMcJytjS47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train set\n",
        "text_train, text_lengths_train, headline_train, headline_lengths_train = data2PaddedArray(text_train, headline_train, {'text_dictionary': text_dictionary,\n",
        "                                                                                                                       'headline_dictionary': headline_dictionary},\n",
        "                                                                                          pre_train_weight)\n",
        "# Validation set\n",
        "text_val, text_lengths_val, headline_val, headline_lengths_val = data2PaddedArray(text_val, headline_val, {'text_dictionary': text_dictionary,\n",
        "                                                                                                           'headline_dictionary': headline_dictionary},\n",
        "                                                                                  pre_train_weight)\n",
        "# Test set\n",
        "text_test, text_lengths_test, headline_test, headline_lengths_test = data2PaddedArray(text_test, headline_test, {'text_dictionary': text_dictionary,\n",
        "                                                                                                                 'headline_dictionary': headline_dictionary},\n",
        "                                                                                       pre_train_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N4c4riOR_Ck",
        "colab_type": "text"
      },
      "source": [
        "# **3 Training**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF6q63I5XpZN",
        "colab_type": "text"
      },
      "source": [
        "## **3.1 Generator - Pretraining**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Description**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUkoLDKlmDkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = {'max_epochs': 3,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 5e-4,\n",
        "        'clip': 10,\n",
        "        'l2_reg': 1e-4,\n",
        "        'model_name': \"generator031\"\n",
        "      }\n",
        "\n",
        "##### model ######\n",
        "OUTPUT_DIM = len(headline_dictionary.index2word.keys())\n",
        "ENC_EMB_DIM = pre_train_weight.shape[1]\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "\n",
        "enc_num_layers = 1 # number of layers in RNN\n",
        "dec_num_layers = 1 # number of layers in RNN\n",
        "\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93vbQiZ7lABE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generator = generator(model = _Seq2Seq, loss_function = nn.CrossEntropyLoss, optimiser = optim.Adam, l2_reg = grid['l2_reg'], batch_size = grid['batch_size'],\n",
        "                      text_dictionary = text_dictionary, embeddings = pre_train_weight, max_epochs = grid['max_epochs'], learning_rate = grid['learning_rate'],\n",
        "                      clip = grid['clip'], teacher_forcing_ratio = 1, OUTPUT_DIM = OUTPUT_DIM, ENC_HID_DIM = ENC_HID_DIM, ENC_EMB_DIM = ENC_EMB_DIM,\n",
        "                      DEC_HID_DIM = DEC_HID_DIM, ENC_DROPOUT = ENC_DROPOUT, DEC_DROPOUT = DEC_DROPOUT, enc_num_layers = enc_num_layers, dec_num_layers = dec_num_layers,\n",
        "                      device = device, model_name = grid['model_name'], push_to_repo = push_to_repo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zuZnRR4a9iK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Generator.load()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8Vkl98zId75",
        "colab_type": "code",
        "outputId": "ae90ae0e-a302-4b65-ddf2-8cb0a3b9a022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "Generator.model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_Seq2Seq(\n",
              "  (encoder): _Encoder(\n",
              "    (rnn): GRU(200, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): _Decoder(\n",
              "    (attention): _Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (rnn): GRU(1224, 512)\n",
              "    (fc_out): Linear(in_features=1736, out_features=13931, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTosh2_RmxiA",
        "colab_type": "code",
        "outputId": "6fe0da70-ae86-4a2f-a437-2d3ba3dfd5ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Generator.train(X_train = text_train,\n",
        "                y_train = headline_train,\n",
        "                X_val = text_val,\n",
        "                y_val = headline_val,\n",
        "                X_train_lengths = text_lengths_train,\n",
        "                y_train_lengths = headline_lengths_train,\n",
        "                X_val_lengths = text_lengths_val,\n",
        "                y_val_lengths = headline_lengths_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 - Intermediate loss 3.292 after 1.97 % of training examples.\n",
            "Total time 60.1 s.\n",
            "Epoch 1 - Intermediate loss 3.038 after 4.33 % of training examples.\n",
            "Total time 120.8 s.\n",
            "Epoch 1 - Intermediate loss 2.925 after 6.84 % of training examples.\n",
            "Total time 181.6 s.\n",
            "Epoch 1 - Intermediate loss 2.856 after 9.34 % of training examples.\n",
            "Total time 242.2 s.\n",
            "Epoch 1 - Intermediate loss 2.801 after 11.95 % of training examples.\n",
            "Total time 304.0 s.\n",
            "Epoch 1 - Intermediate loss 2.756 after 14.40 % of training examples.\n",
            "Total time 364.6 s.\n",
            "Epoch 1 - Intermediate loss 2.724 after 17.04 % of training examples.\n",
            "Total time 425.2 s.\n",
            "Epoch 1 - Intermediate loss 2.682 after 19.65 % of training examples.\n",
            "Total time 485.9 s.\n",
            "Epoch 1 - Intermediate loss 2.646 after 22.29 % of training examples.\n",
            "Total time 546.3 s.\n",
            "Epoch 1 - Intermediate loss 2.611 after 24.85 % of training examples.\n",
            "Total time 607.2 s.\n",
            "Epoch 1 - Intermediate loss 2.579 after 27.40 % of training examples.\n",
            "Total time 667.6 s.\n",
            "Epoch 1 - Intermediate loss 2.554 after 30.23 % of training examples.\n",
            "Total time 728.9 s.\n",
            "Epoch 1 - Intermediate loss 2.527 after 32.81 % of training examples.\n",
            "Total time 789.6 s.\n",
            "Epoch 1 - Intermediate loss 2.509 after 35.69 % of training examples.\n",
            "Total time 850.4 s.\n",
            "Epoch 1 - Intermediate loss 2.488 after 38.55 % of training examples.\n",
            "Total time 911.0 s.\n",
            "Epoch 1 - Intermediate loss 2.470 after 41.29 % of training examples.\n",
            "Total time 971.8 s.\n",
            "Epoch 1 - Intermediate loss 2.456 after 44.15 % of training examples.\n",
            "Total time 1032.4 s.\n",
            "Epoch 1 - Intermediate loss 2.440 after 46.86 % of training examples.\n",
            "Total time 1093.0 s.\n",
            "Epoch 1 - Intermediate loss 2.426 after 49.83 % of training examples.\n",
            "Total time 1153.5 s.\n",
            "Epoch 1 - Intermediate loss 2.414 after 52.92 % of training examples.\n",
            "Total time 1213.9 s.\n",
            "Epoch 1 - Intermediate loss 2.397 after 55.64 % of training examples.\n",
            "Total time 1274.4 s.\n",
            "Epoch 1 - Intermediate loss 2.385 after 58.47 % of training examples.\n",
            "Total time 1335.0 s.\n",
            "Epoch 1 - Intermediate loss 2.373 after 61.45 % of training examples.\n",
            "Total time 1395.7 s.\n",
            "Epoch 1 - Intermediate loss 2.361 after 64.39 % of training examples.\n",
            "Total time 1456.6 s.\n",
            "Epoch 1 - Intermediate loss 2.348 after 67.24 % of training examples.\n",
            "Total time 1517.1 s.\n",
            "Epoch 1 - Intermediate loss 2.338 after 70.39 % of training examples.\n",
            "Total time 1578.0 s.\n",
            "Epoch 1 - Intermediate loss 2.329 after 73.49 % of training examples.\n",
            "Total time 1638.7 s.\n",
            "Epoch 1 - Intermediate loss 2.318 after 76.64 % of training examples.\n",
            "Total time 1699.2 s.\n",
            "Epoch 1 - Intermediate loss 2.309 after 80.03 % of training examples.\n",
            "Total time 1760.0 s.\n",
            "Epoch 1 - Intermediate loss 2.299 after 83.34 % of training examples.\n",
            "Total time 1820.5 s.\n",
            "Epoch 1 - Intermediate loss 2.293 after 86.92 % of training examples.\n",
            "Total time 1881.0 s.\n",
            "Epoch 1 - Intermediate loss 2.295 after 90.90 % of training examples.\n",
            "Total time 1941.5 s.\n",
            "Epoch 1 - Intermediate loss 2.307 after 95.59 % of training examples.\n",
            "Total time 2002.0 s.\n",
            "Epoch: 1:\n",
            "Train Loss: 2.356\n",
            "Validation Loss: 2.327\n",
            "M\tResults/generator00__train_time.txt\n",
            "Already on 'master'\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 8 (delta 2), reused 7 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n",
            "From https://github.com/stancld/GeneratingHeadline_GANs\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Updating cd0e41d..74575bd\n",
            "Fast-forward\n",
            " Code/Models/.DS_Store                              | Bin \u001b[31m0\u001b[m -> \u001b[32m6148\u001b[m bytes\n",
            " .../{CNN_discriminator.py => CNN_text_clf.py}      | 261 \u001b[32m+++++++\u001b[m\u001b[31m--------\u001b[m\n",
            " Code/Models/discriminator.py                       | 258 \u001b[31m---------------\u001b[m\n",
            " Code/Models/discriminator_training_class.py        | 349 \u001b[32m++++++++++++++++\u001b[m\u001b[31m-----\u001b[m\n",
            " 4 files changed, 396 insertions(+), 472 deletions(-)\n",
            " create mode 100644 Code/Models/.DS_Store\n",
            " rename Code/Models/{CNN_discriminator.py => CNN_text_clf.py} (62%)\n",
            " delete mode 100644 Code/Models/discriminator.py\n",
            "error: pathspec 'models_branch' did not match any file(s) known to git.\n",
            "[master c920e45] model state update\n",
            " 5 files changed, 6 insertions(+), 1 deletion(-)\n",
            " create mode 100644 Results/generator031__train_loss.txt\n",
            " create mode 100644 Results/generator031__train_time.txt\n",
            " create mode 100644 Results/generator031__training_time.txt\n",
            " create mode 100644 Results/generator031__validation_loss.txt\n",
            "Already on 'master'\n",
            "merge: models_branch - not something we can merge\n",
            "Counting objects: 8, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (8/8), 638 bytes | 106.00 KiB/s, done.\n",
            "Total 8 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/stancld/GeneratingHeadline_GANs.git\n",
            "   74575bd..c920e45  master -> master\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Epoch 2 - Intermediate loss 2.916 after 0.03 % of training examples.\n",
            "Total time 2240.9 s.\n",
            "Epoch 2 - Intermediate loss 2.029 after 1.97 % of training examples.\n",
            "Total time 2301.7 s.\n",
            "Epoch 2 - Intermediate loss 2.129 after 4.33 % of training examples.\n",
            "Total time 2362.1 s.\n",
            "Epoch 2 - Intermediate loss 2.157 after 6.81 % of training examples.\n",
            "Total time 2422.8 s.\n",
            "Epoch 2 - Intermediate loss 2.175 after 9.34 % of training examples.\n",
            "Total time 2483.3 s.\n",
            "Epoch 2 - Intermediate loss 2.185 after 11.95 % of training examples.\n",
            "Total time 2544.0 s.\n",
            "Epoch 2 - Intermediate loss 2.182 after 14.43 % of training examples.\n",
            "Total time 2605.1 s.\n",
            "Epoch 2 - Intermediate loss 2.187 after 17.12 % of training examples.\n",
            "Total time 2666.0 s.\n",
            "Epoch 2 - Intermediate loss 2.180 after 19.78 % of training examples.\n",
            "Total time 2726.5 s.\n",
            "Epoch 2 - Intermediate loss 2.170 after 22.42 % of training examples.\n",
            "Total time 2787.1 s.\n",
            "Epoch 2 - Intermediate loss 2.158 after 25.06 % of training examples.\n",
            "Total time 2848.8 s.\n",
            "Epoch 2 - Intermediate loss 2.149 after 27.73 % of training examples.\n",
            "Total time 2909.8 s.\n",
            "Epoch 2 - Intermediate loss 2.143 after 30.42 % of training examples.\n",
            "Total time 2970.2 s.\n",
            "Epoch 2 - Intermediate loss 2.131 after 33.00 % of training examples.\n",
            "Total time 3031.1 s.\n",
            "Epoch 2 - Intermediate loss 2.128 after 35.91 % of training examples.\n",
            "Total time 3091.6 s.\n",
            "Epoch 2 - Intermediate loss 2.122 after 38.71 % of training examples.\n",
            "Total time 3152.1 s.\n",
            "Epoch 2 - Intermediate loss 2.117 after 41.48 % of training examples.\n",
            "Total time 3212.8 s.\n",
            "Epoch 2 - Intermediate loss 2.116 after 44.33 % of training examples.\n",
            "Total time 3273.8 s.\n",
            "Epoch 2 - Intermediate loss 2.110 after 47.13 % of training examples.\n",
            "Total time 3334.3 s.\n",
            "Epoch 2 - Intermediate loss 2.109 after 50.12 % of training examples.\n",
            "Total time 3395.1 s.\n",
            "Epoch 2 - Intermediate loss 2.104 after 53.08 % of training examples.\n",
            "Total time 3455.7 s.\n",
            "Epoch 2 - Intermediate loss 2.097 after 55.85 % of training examples.\n",
            "Total time 3516.7 s.\n",
            "Epoch 2 - Intermediate loss 2.093 after 58.71 % of training examples.\n",
            "Total time 3577.1 s.\n",
            "Epoch 2 - Intermediate loss 2.089 after 61.67 % of training examples.\n",
            "Total time 3637.9 s.\n",
            "Epoch 2 - Intermediate loss 2.084 after 64.60 % of training examples.\n",
            "Total time 3698.5 s.\n",
            "Epoch 2 - Intermediate loss 2.081 after 67.56 % of training examples.\n",
            "Total time 3759.1 s.\n",
            "Epoch 2 - Intermediate loss 2.077 after 70.55 % of training examples.\n",
            "Total time 3819.8 s.\n",
            "Epoch 2 - Intermediate loss 2.074 after 73.62 % of training examples.\n",
            "Total time 3880.4 s.\n",
            "Epoch 2 - Intermediate loss 2.070 after 76.77 % of training examples.\n",
            "Total time 3941.1 s.\n",
            "Epoch 2 - Intermediate loss 2.068 after 80.08 % of training examples.\n",
            "Total time 4001.9 s.\n",
            "Epoch 2 - Intermediate loss 2.064 after 83.34 % of training examples.\n",
            "Total time 4062.6 s.\n",
            "Epoch 2 - Intermediate loss 2.065 after 86.84 % of training examples.\n",
            "Total time 4123.1 s.\n",
            "Epoch 2 - Intermediate loss 2.073 after 90.71 % of training examples.\n",
            "Total time 4183.5 s.\n",
            "Epoch 2 - Intermediate loss 2.090 after 95.29 % of training examples.\n",
            "Total time 4244.0 s.\n",
            "Epoch: 2:\n",
            "Train Loss: 2.145\n",
            "Validation Loss: 2.250\n",
            "M\tResults/generator031__train_loss.txt\n",
            "M\tResults/generator031__train_time.txt\n",
            "M\tResults/generator031__training_time.txt\n",
            "M\tResults/generator031__validation_loss.txt\n",
            "Already on 'master'\n",
            "From https://github.com/stancld/GeneratingHeadline_GANs\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Already up to date.\n",
            "error: pathspec 'models_branch' did not match any file(s) known to git.\n",
            "[master 1c11d60] model state update\n",
            " 4 files changed, 4 insertions(+), 2 deletions(-)\n",
            "Already on 'master'\n",
            "merge: models_branch - not something we can merge\n",
            "Counting objects: 7, done.\n",
            "Delta compression using up to 4 threads.\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (7/7), 565 bytes | 141.00 KiB/s, done.\n",
            "Total 7 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/stancld/GeneratingHeadline_GANs.git\n",
            "   c920e45..1c11d60  master -> master\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n",
            "Epoch 3 - Intermediate loss 2.813 after 0.03 % of training examples.\n",
            "Total time 4485.4 s.\n",
            "Epoch 3 - Intermediate loss 1.967 after 2.05 % of training examples.\n",
            "Total time 4545.9 s.\n",
            "Epoch 3 - Intermediate loss 2.049 after 4.44 % of training examples.\n",
            "Total time 4606.9 s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcO4oJtvGNIX",
        "colab_type": "text"
      },
      "source": [
        "## **3.2 Generator - Generating summaries**\n",
        "\n",
        "<hr>\n",
        "\n",
        "**Description**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU_PgAn2wazh",
        "colab_type": "code",
        "outputId": "8ec3192c-4e60-4971-8442-2834b04bf897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "\"\"\"\n",
        "!git pull origin master\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/stancld/GeneratingHeadline_GANs\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   32913f2..769693e  master     -> origin/master\n",
            "Updating 32913f2..769693e\n",
            "Fast-forward\n",
            " Code/Models/generator_training_class.py | 7 \u001b[32m+++\u001b[m\u001b[31m----\u001b[m\n",
            " 1 file changed, 3 insertions(+), 4 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScNVzbrRG7uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "# code for the training class\n",
        "run Code/Models/generator_training_class.py\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1MDzAFlHNDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "o = Generator.generate_summaries(input_val = text_train,\n",
        "                             input_val_lengths = text_lengths_train,\n",
        "                             target_val = headline_train,\n",
        "                             target_val_lengths = headline_lengths_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW9mkFPVHoLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_ix = headline_dictionary.word2index['<pad>']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Z_-Qm1I2B1",
        "colab_type": "code",
        "outputId": "3bd4b882-ecbf-409f-ef4b-2a8f0961667d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "for k in range(10):\n",
        "  print(' '.join([headline_dictionary.index2word[i] for i in o[:, k] if i != pad_ix]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "suckle tap the red . eos\n",
            "suckle integrate the 4 . eos\n",
            "suckle dial 1 4 1 . eos\n",
            "suckle cut the brim . eos\n",
            "suckle choose a circle . eos\n",
            "suckle wash your hands . eos\n",
            "suckle wash your hair . eos\n",
            "suckle tap the three . eos\n",
            "suckle add the water . eos\n",
            "suckle done . eos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caei5JfqJtiZ",
        "colab_type": "code",
        "outputId": "ddda59b4-8386-421b-f663-0167358c018f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "for k in range(10):\n",
        "  print(' '.join([headline_dictionary.index2word[i] for i in headline_train[:, k] if i != pad_ix]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sos click on the sound again with your right mouse button and click on modify lip sync mapping . eos\n",
            "sos identify all common prime factors . eos\n",
            "sos input the column headings input base t to three . eos\n",
            "sos cut the wire mesh large enough to fold around the box .be sure you allow for some overlap at the seam . eos\n",
            "sos cut out another 5 items that are sold by quantity . eos\n",
            "sos look out when the bear comes to eat the three three ! eos\n",
            "sos mavis s hair is a bob kind of style with bangs . eos\n",
            "sos do not overdo three . eos\n",
            "sos add beer to the glass . eos\n",
            "sos if you get accepted at your three . eos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukhnYw7CM-M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "`Generator.text_dictionary.word2index['sos']"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}